{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLizard PyTorch Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4., 12.,  5.,  4.]) torch.Size([4])\n",
      "tensor([[ 3., 11., 10.,  8.],\n",
      "        [14.,  8.,  8.,  1.],\n",
      "        [ 5.,  9.,  3.,  7.],\n",
      "        [15., 15.,  5.,  8.],\n",
      "        [ 8., 13., 17.,  2.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([226., 196., 171., 297., 281.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Video 1\n",
    "# Torch tensor multiplication\n",
    "a = torch.tensor([4,12,5,4],dtype = torch.float32)\n",
    "print(a,a.shape)\n",
    "b = torch.randint(0,20,size=(5,4),dtype=torch.float32)\n",
    "print(b)\n",
    "b.matmul(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2378, -0.3530, -0.0535, -0.0147],\n",
       "        [-0.1691, -0.3778,  0.2041, -0.0449],\n",
       "        [ 0.2840,  0.4596, -0.2715,  0.4295],\n",
       "        [ 0.1316, -0.1160, -0.1368,  0.2888],\n",
       "        [ 0.3611, -0.3528,  0.2873, -0.1007]], requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = nn.Linear(4,5,bias = False)\n",
    "fc(a) # passing the input to the hiidden la\n",
    "fc.weight # these are the random assigned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([226., 196., 171., 297., 281.], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting the weight to the predefined one\n",
    "fc.weight = nn.Parameter(b)\n",
    "fc(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(20)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRin number of elements within the tensors\n",
    "print(b.numel())\n",
    "torch.tensor(b.shape).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3., 11., 10.,  8., 14.,  8.,  8.,  1.,  5.,  9.,  3.,  7., 15., 15.,\n",
      "         5.,  8.,  8., 13., 17.,  2.])\n"
     ]
    }
   ],
   "source": [
    "# implementing flatten function\n",
    "def flatten(t):\n",
    "    t = t.reshape(-1)\n",
    "    return t\n",
    "print(flatten(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n",
      "tensor([[1., 2., 5., 6.],\n",
      "        [3., 4., 7., 8.]])\n",
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.]],\n",
      "\n",
      "        [[ 5.,  6.],\n",
      "         [ 7.,  8.]],\n",
      "\n",
      "        [[ 9., 10.],\n",
      "         [11., 12.]]])\n"
     ]
    }
   ],
   "source": [
    "# concat tensors into different dimenstions\n",
    "t1 = torch.tensor([[1,2],[3,4]],dtype=torch.float32)\n",
    "t2 = torch.tensor([[5,6],[7,8]],dtype=torch.float32)\n",
    "t3 = torch.tensor([[9,10],[11,12]],dtype=torch.float32)\n",
    "# dim 0 concat\n",
    "print(torch.cat((t1,t2)))\n",
    "# dim 1 concat\n",
    "print(torch.cat((t1,t2),dim=1))\n",
    "# stack is used to merge tensors channel wise\n",
    "print(torch.stack((t1,t2,t3)))  # <----- imp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dummy model\n",
    "* adding 2 conv layer \n",
    "* adding 2 dense layer\n",
    "* implementing forward pass operation\n",
    "* generate a fake tensor and pass through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Network(\n",
      "  (conv1): Conv2d(1, 5, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(5, 4, kernel_size=(3, 3), stride=(3, 3))\n",
      "  (fc1): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (out): Linear(in_features=10, out_features=5, bias=True)\n",
      ")>\n",
      "torch.Size([1, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 4.1054, 0.7554, 6.2099, 2.5689])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=5,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(5,4,kernel_size=3,stride =3) #(8,8) output\n",
    "        self.fc1 = nn.Linear(4*4*4,10)\n",
    "        self.out = nn.Linear(10,5)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = x.reshape(-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.relu(self.out(x))\n",
    "\n",
    "    \n",
    "torch.set_grad_enabled(False)  # stop the computational graph calculation\n",
    "\n",
    "    \n",
    "net = Network() # Model initialized\n",
    "print(net.parameters)   # display the parameters of the model\n",
    "\n",
    "\n",
    "# generate demo image\n",
    "image = torch.randint(0,255,(1,28,28),dtype = torch.float32).unsqueeze(dim=0)\n",
    "print(image.shape)\n",
    "\n",
    "# pass the image from the network\n",
    "net(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep NN Model to predict the function ouput\n",
    "## Make NN with dense structure\n",
    "- 3 linear layer\n",
    "- generater data generating fucntion and load it with data loader\n",
    "* iterate and run epochs \n",
    "* plot the accuracy and loss curves`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FuncApproximator(\n",
       "  (fc1): Linear(in_features=2, out_features=5, bias=True)\n",
       "  (out): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the Liner model \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class FuncApproximator(nn.Module):\n",
    "    def __init__(self,input_features,output_features):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_features,5)\n",
    "        self.out = nn.Linear(5,output_features)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        return self.out(x)\n",
    "torch.set_grad_enabled(True)\n",
    "net = FuncApproximator(2,1)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset generation\n",
    "def gen_dataset(samples):\n",
    "    a = torch.randn(size =(samples,2),dtype = torch.float32)\n",
    "    # the function defined\n",
    "    \n",
    "#     print(a.shape)\n",
    "    c = 2*a[:,0]+5*a[:,1]\n",
    "#     print(c)\n",
    "#     a = a.unsqueeze(dim=0)\n",
    "#     print(a.shape, c.shape)\n",
    "#     d = torch.from_numpy(np.array([a.numpy(),c.numpy()]))\n",
    "#     print(d)\n",
    "#     print(d.shape)\n",
    "    return (a,c) #torch.cat( (a.unsqueeze(0).t(),c),dim=0)\n",
    "tx,ty = gen_dataset(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(),lr = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty = ty.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossM = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0 .. loss : 63714.04568270729 \n",
      "epochs: 1 .. loss : 1126248.7258909005 \n",
      "epochs: 2 .. loss : 57.80890582227856 \n",
      "epochs: 3 .. loss : 244006.9051575576 \n",
      "epochs: 4 .. loss : 9.442334830689347e-10 \n",
      "epochs: 5 .. loss : 1.0381388110269896e-09 \n",
      "epochs: 6 .. loss : 1.14101442877379e-08 \n",
      "epochs: 7 .. loss : 1449.0028505587711 \n",
      "epochs: 8 .. loss : 293.66410333112447 \n",
      "epochs: 9 .. loss : 3455282.8287907606 \n",
      "epochs: 10 .. loss : 1.561834074570445e-08 \n",
      "epochs: 11 .. loss : 3.593939715273997e-09 \n",
      "epochs: 12 .. loss : 0.0013838356388997664 \n",
      "epochs: 13 .. loss : 9616.114167461243 \n",
      "epochs: 14 .. loss : 1.109148723005271e-07 \n"
     ]
    }
   ],
   "source": [
    "# main loop\n",
    "epochs = 15\n",
    "for epoch_ in range(epochs):\n",
    "    total_loss = 0\n",
    "    for i,j in zip(tx,ty):\n",
    "        optimizer.zero_grad()\n",
    "        pred = net(i)\n",
    "        loss = lossM(pred,j)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epochs: {epoch_} .. loss : {total_loss} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
