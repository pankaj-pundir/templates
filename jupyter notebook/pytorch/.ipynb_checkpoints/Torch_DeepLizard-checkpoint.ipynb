{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLizard PyTorch Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4., 12.,  5.,  4.]) torch.Size([4])\n",
      "tensor([[ 3., 11., 10.,  8.],\n",
      "        [14.,  8.,  8.,  1.],\n",
      "        [ 5.,  9.,  3.,  7.],\n",
      "        [15., 15.,  5.,  8.],\n",
      "        [ 8., 13., 17.,  2.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([226., 196., 171., 297., 281.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Video 1\n",
    "# Torch tensor multiplication\n",
    "a = torch.tensor([4,12,5,4],dtype = torch.float32)\n",
    "print(a,a.shape)\n",
    "b = torch.randint(0,20,size=(5,4),dtype=torch.float32)\n",
    "print(b)\n",
    "b.matmul(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2378, -0.3530, -0.0535, -0.0147],\n",
       "        [-0.1691, -0.3778,  0.2041, -0.0449],\n",
       "        [ 0.2840,  0.4596, -0.2715,  0.4295],\n",
       "        [ 0.1316, -0.1160, -0.1368,  0.2888],\n",
       "        [ 0.3611, -0.3528,  0.2873, -0.1007]], requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = nn.Linear(4,5,bias = False)\n",
    "fc(a) # passing the input to the hiidden la\n",
    "fc.weight # these are the random assigned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([226., 196., 171., 297., 281.], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting the weight to the predefined one\n",
    "fc.weight = nn.Parameter(b)\n",
    "fc(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(20)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRin number of elements within the tensors\n",
    "print(b.numel())\n",
    "torch.tensor(b.shape).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3., 11., 10.,  8., 14.,  8.,  8.,  1.,  5.,  9.,  3.,  7., 15., 15.,\n",
      "         5.,  8.,  8., 13., 17.,  2.])\n"
     ]
    }
   ],
   "source": [
    "# implementing flatten function\n",
    "def flatten(t):\n",
    "    t = t.reshape(-1)\n",
    "    return t\n",
    "print(flatten(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n",
      "tensor([[1., 2., 5., 6.],\n",
      "        [3., 4., 7., 8.]])\n",
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.]],\n",
      "\n",
      "        [[ 5.,  6.],\n",
      "         [ 7.,  8.]],\n",
      "\n",
      "        [[ 9., 10.],\n",
      "         [11., 12.]]])\n"
     ]
    }
   ],
   "source": [
    "# concat tensors into different dimenstions\n",
    "t1 = torch.tensor([[1,2],[3,4]],dtype=torch.float32)\n",
    "t2 = torch.tensor([[5,6],[7,8]],dtype=torch.float32)\n",
    "t3 = torch.tensor([[9,10],[11,12]],dtype=torch.float32)\n",
    "# dim 0 concat\n",
    "print(torch.cat((t1,t2)))\n",
    "# dim 1 concat\n",
    "print(torch.cat((t1,t2),dim=1))\n",
    "# stack is used to merge tensors channel wise\n",
    "print(torch.stack((t1,t2,t3)))  # <----- imp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dummy model\n",
    "* adding 2 conv layer \n",
    "* adding 2 dense layer\n",
    "* implementing forward pass operation\n",
    "* generate a fake tensor and pass through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Network(\n",
      "  (conv1): Conv2d(1, 5, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(5, 4, kernel_size=(3, 3), stride=(3, 3))\n",
      "  (fc1): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (out): Linear(in_features=10, out_features=5, bias=True)\n",
      ")>\n",
      "torch.Size([1, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 4.1054, 0.7554, 6.2099, 2.5689])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=5,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(5,4,kernel_size=3,stride =3) #(8,8) output\n",
    "        self.fc1 = nn.Linear(4*4*4,10)\n",
    "        self.out = nn.Linear(10,5)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = x.reshape(-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.relu(self.out(x))\n",
    "\n",
    "    \n",
    "torch.set_grad_enabled(False)  # stop the computational graph calculation\n",
    "\n",
    "    \n",
    "net = Network() # Model initialized\n",
    "print(net.parameters)   # display the parameters of the model\n",
    "\n",
    "\n",
    "# generate demo image\n",
    "image = torch.randint(0,255,(1,28,28),dtype = torch.float32).unsqueeze(dim=0)\n",
    "print(image.shape)\n",
    "\n",
    "# pass the image from the network\n",
    "net(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
