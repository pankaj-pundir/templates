{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I41KgTd_dE9Y"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcr3Cb4nPIwU"
   },
   "source": [
    "# Learn And implement Pytorch Part - 1\n",
    "---\n",
    "\n",
    "## Kaggle competitions\n",
    "\n",
    "![alt text](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/02/pytorch-logo-flat-300x210.png)\n",
    "\n",
    "#### Important Links\n",
    "* https://towardsdatascience.com/a-beginners-tutorial-on-building-an-ai-image-classifier-using-pytorch-6f85cb69cba7\n",
    "\n",
    "* https://www.kaggle.com/carloalbertobarbano/vgg16-transfer-learning-pytorch\n",
    "* http://scikit-image.org/docs/dev/user_guide/numpy_images.html\n",
    "\n",
    "\n",
    "*By Pankaj Pundir*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5fVxTr_DAFy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UqsH6b7pC-8b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOifJyv_S8d3"
   },
   "source": [
    "# google drive access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjzrTuzFfP1Z"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir(\"drive/My Drive/Colab Notebooks/pyTorch\")\n",
    "\n",
    "# installing pytorch and torchvision\n",
    "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
    "!pip3 install torchvision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tzfKRYcsOfC_"
   },
   "source": [
    "# Import **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3RGqYa_fqGz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/alvin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/alvin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/alvin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/alvin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# basic imports of pyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# transfer learning model import\n",
    "from torchvision import models\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# some sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "# basic python imports\n",
    "import cv2, os , sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHCidGr8EnIn"
   },
   "source": [
    "## torch information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ac8zqeFDEloG"
   },
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# print device properties \n",
    "print(torch.cuda.get_device_properties(0))\n",
    "\n",
    "\n",
    "# empty the cache of cuda\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JfsMjBt3L7E6"
   },
   "source": [
    "# Data  Loading - and accessibility \n",
    "Robust Class method **bold text**\n",
    "\n",
    "\n",
    "\n",
    "*   provide Train & test option.\n",
    "*   The data is provided as generator thus saves memory.\n",
    "* preprocessing is adjustable with ** **bold text** cv2**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUwKG7t5MfOQ"
   },
   "outputs": [],
   "source": [
    "class CustomedDataSet(torch.utils.data.Dataset):\n",
    "  \n",
    "    def __init__(self, train=True):\n",
    "        self.train = train\n",
    "        self.train_loc = '../input/train.csv'\n",
    "        self.test_loc = '../input/test.csv'\n",
    "        \n",
    "        if self.train :\n",
    "            trainX = pd.read_csv(self.train_loc)\n",
    "            \n",
    "            trainY = trainX.label.values.tolist()\n",
    "            \n",
    "            trainX = np.apply_along_axis(self.preprocess , axis=1 ,\\\n",
    "                  arr = trainX.drop('label',axis=1).values.reshape(trainX.shape[0], 1, 28, 28).astype(np.uint8))\n",
    "            \n",
    "            # storing data to the list\n",
    "            self.datalist = trainX\n",
    "            self.labellist = trainY\n",
    "       \n",
    "        else:\n",
    "            testX = pd.read_csv(self.test_loc)\n",
    "            testX = testX.values.reshape(testX.shape[0], 1, 28, 28)\n",
    "            self.datalist = testX\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # train - provide Xtrain and Ytrain\n",
    "        \n",
    "        if self.train:\n",
    "            return torch.Tensor(self.datalist[index].astype(float)), self.labellist[index]\n",
    "        else:\n",
    "            return torch.Tensor(self.datalist[index].astype(float))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.datalist.shape[0]\n",
    "    \n",
    "    def preprocess(self,img):\n",
    "        '''\n",
    "        Apply transformation that are not implicitly provided in the\n",
    "        pytorch inbuilt functions.\n",
    "        '''\n",
    "        \n",
    "        print(img.shape)\n",
    "        blur = cv2.GaussianBlur(img,(3,3),0)\n",
    "        ret3,th3 = cv2.threshold(blur,120,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        return img\n",
    "      \n",
    "      \n",
    "   \n",
    "        \n",
    "# should be initialized once -or delete previos instance of \n",
    "# object as increased in size and RAM consumption\n",
    "\n",
    "train_dataset = CustomedDataSet()\n",
    "test_dataset = CustomedDataSet(train=False)\n",
    "\n",
    "sys.getsizeof(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KrnbiLmoUN35"
   },
   "source": [
    "### Updated functionality of Custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tlqqy7k3UMqR"
   },
   "outputs": [],
   "source": [
    "   \n",
    "class CustomedDataSet(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    CustomedDataSet provide the data to be converted to\n",
    "    train, validation and test set.\n",
    "    num_rows = (1000,1500) - select the set of rows\n",
    "    train = bool - composes of train and validation\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, train=True, num_rows = (0,10) ):\n",
    "        self.train = train\n",
    "        \n",
    "        self.datalist =[]\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "        np.uint8,\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(size=(224,224), interpolation = 2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.train :\n",
    "            trainX = pd.read_csv('../input/train.csv',nrows = num_rows[1])\n",
    "            trainX = trainX.iloc[num_rows[0]:,:]\n",
    "            trainY = trainX.label.values.tolist()\n",
    "            arr = trainX.drop('label',axis=1).values.reshape(trainX.shape[0],  28, 28).astype(np.uint8)\n",
    "            for i in arr:\n",
    "                self.datalist.append(self.preprocess(i))\n",
    "        \n",
    "            self.datalist = torch.stack(self.datalist)\n",
    "            self.labellist = trainY\n",
    "            if num_rows[0] != 0:\n",
    "                print(f\"Validation Data : {trainX.shape}\")\n",
    "            else:\n",
    "                print(f\"Training Data : {trainX.shape}\")\n",
    "            \n",
    "        else:\n",
    "            testX = pd.read_csv('../input/test.csv', nrows = num_rows[1])\n",
    "            testX = testX.values.reshape(testX.shape[0], 28, 28).astype(np.uint8)\n",
    "            for i in testX:\n",
    "                self.datalist.append(self.preprocess(i))\n",
    "        \n",
    "            self.datalist = torch.stack(self.datalist)\n",
    "#             self.datalist = testX\n",
    "            print(f\"Testing Data : {testX.shape}\")\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            return torch.Tensor(self.datalist[index]),self.labellist[index]\n",
    "        else:\n",
    "            return torch.Tensor(self.datalist[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.datalist.shape[0]\n",
    "    \n",
    "    def preprocess(self,img):\n",
    "        '''\n",
    "        For tansfer learning apply\n",
    "        1. gray to BGR\n",
    "        2. transform to min crop 224\n",
    "        3. to tensor\n",
    "        \n",
    "        currently implemented in this function\n",
    "        '''\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDqO6wLBOmO1"
   },
   "source": [
    "## Data Augmentation - Image\n",
    "\n",
    "> invalid dim occur in images due to numpy and cv2 repr\n",
    "of images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lkz0yJoIL6cG"
   },
   "outputs": [],
   "source": [
    "# Image transformations & data augmentation\n",
    "\n",
    "image_transforms = {\n",
    "    # Train uses data augmentation\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        \n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    \n",
    "    # Validation does not use augmentation\n",
    "    'valid':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256), \n",
    "        # resizes the images so the shortest side has a length of 255 pixels. \n",
    "        # The other side is scaled to maintain the aspect ratio of the image.\n",
    "        \n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0xLRpC7nRBoB"
   },
   "source": [
    "## Data Loading to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ycfEAquQBZf"
   },
   "outputs": [],
   "source": [
    "# creating Data Loader\n",
    "\n",
    "# using CustomDataSet\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "len_train_loader = len(train_dataset)\n",
    "\n",
    "del train_dataset, test_dataset\n",
    "\n",
    "\n",
    "# Datasets from folders & applying data_transformation\n",
    "\n",
    "traindir = ''\n",
    "validdir = ''\n",
    "\n",
    "data = {\n",
    "    'train':\n",
    "    datasets.ImageFolder(root=traindir, transform=image_transforms['train']),\n",
    "    'valid':\n",
    "    datasets.ImageFolder(root=validdir, transform=image_transforms['valid']),\n",
    "}\n",
    "\n",
    "# Dataloader iterators, make sure to shuffle\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(data['valid'], batch_size=batch_size, shuffle=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QuQ18rFmH5-P"
   },
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cea1enu6H497"
   },
   "outputs": [],
   "source": [
    "# make iterable object to display the cluster of images\n",
    "# within the batch\n",
    "images, labels = iter(train_loader).next()\n",
    "\n",
    "# provide graid view\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.title(labels.numpy());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWn2FKC1H5Bb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLh6RrIGSuH_"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2RyYMqeTMK3"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qg-peL2pKxUz"
   },
   "source": [
    "## Transfer learning pretrained weights\n",
    "  \n",
    "\n",
    "1.   Loading Pretrained Weights\n",
    "\n",
    " press **tab** after models. to get the list\n",
    " \n",
    " *All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6tDkFljSZ3nU"
   },
   "outputs": [],
   "source": [
    "# downloading the moadel to RAM\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8kvaSAO0r_mM"
   },
   "outputs": [],
   "source": [
    "# setting training to false\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# model.classifier\n",
    "# model.features\n",
    "\n",
    "\n",
    "''' n_classes the number of final neurons \n",
    "(for categories -  total number of possible output)\n",
    "'''\n",
    "\n",
    "model.classifier[6] = nn.Sequential(\n",
    "                      nn.Linear(4096, 256), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(256, n_classes),                   \n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88oSgo9sRcex"
   },
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*0W310-cMNHPWjErqPuGXpw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_sfvmfHKSAIp"
   },
   "source": [
    "## Self Customizable Convolution model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjF7bDKzR-nt"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1 ,8, kernel_size=3,padding=2),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(8, 32, kernel_size=5,padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, kernel_size=5,padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "cnn = CNN()\n",
    "cnn.cuda()\n",
    "\n",
    "# 784 the number of processed neurons can be found by\n",
    "# doing a trial run instead of calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRUBdiYBsdzy"
   },
   "outputs": [],
   "source": [
    "# Move to gpu\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Distribute across 2 gpus\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 975,
     "status": "ok",
     "timestamp": 1547744442221,
     "user": {
      "displayName": "Pankaj Pundir",
      "photoUrl": "",
      "userId": "12951077964743328573"
     },
     "user_tz": -390
    },
    "id": "kObPV1YFwer6",
    "outputId": "c6ee6ece-d588-44f1-c24e-eabe51dcbf4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138,357,544 total parameters.\n",
      "0 training parameters.\n"
     ]
    }
   ],
   "source": [
    "# information about training parameters\n",
    "\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CXhmNvMwX7EY"
   },
   "source": [
    "# Loss and Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XiBbVxRtwayT"
   },
   "outputs": [],
   "source": [
    "criteration = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters()) # auto adjustment of learning rate\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), \\\n",
    "                            lr=learning_rate, \\\n",
    "                            momentum=0.05)  #faster descent, avoid local minimum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ucl22fLvZAK2"
   },
   "source": [
    "# Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M9zXYkuQa8As"
   },
   "source": [
    "## General data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yY6DJjvds22D"
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  \n",
    "  for i, (data, targets) in enumerate(trainloader):\n",
    "    # Generate predictions\n",
    "    out = model(data)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = criterion(out, targets)\n",
    "    \n",
    "    # change gradients to 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update model parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # display data\n",
    "    if (i+1) % 10 == 0:\n",
    "      print('Loss %.4f' %( loss.data))\n",
    "      print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' %(epoch+1,\n",
    "           num_epochs, i+1, len_train_loader//batch_size, loss.itme()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FmBjzXeccTxR"
   },
   "source": [
    "### with Early stopping method\n",
    "*  *to avoid overfitting of data*\n",
    "* should be used preferably\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMLLZ32pxISY"
   },
   "outputs": [],
   "source": [
    "# Early stopping details\n",
    "\n",
    "n_epochs_stop = 5\n",
    "min_val_loss = np.Inf\n",
    "epochs_no_improve = 5\n",
    "\n",
    "checkpoint_path = \"./\"\n",
    "\n",
    "# Main loop\n",
    "for epoch in range(n_epochs):\n",
    "  # Initialize validation loss for epoch\n",
    "  val_loss = 0\n",
    "  \n",
    "  # Training loop\n",
    "  for data, targets in trainloader:\n",
    "    # Generate predictions\n",
    "    out = model(data)\n",
    "    loss = criterion(out, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "  # Validation loop\n",
    "  for data, targets in validloader:\n",
    "    # Generate predictions \n",
    "    out = model(data)\n",
    "    loss = criterion(out, targets)\n",
    "    val_loss += loss\n",
    "\n",
    "  # Average validation loss\n",
    "  val_loss = val_loss / len(trainloader)\n",
    "\n",
    "  # If the validation loss is at a minimum\n",
    "  if val_loss < min_val_loss:\n",
    "    # Save the model\n",
    "    torch.save(model, checkpoint_path)\n",
    "    epochs_no_improve = 0\n",
    "    min_val_loss = val_loss\n",
    "\n",
    "  else:\n",
    "    epochs_no_improve += 1\n",
    "    # Check early stopping condition\n",
    "    if epochs_no_improve == n_epochs_stop:\n",
    "      print('Early stopping!')\n",
    "\n",
    "      # Load in the best model\n",
    "      model = torch.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ocmsqGGCbMar"
   },
   "source": [
    "## image data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7O45QPgWbBqo"
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "      \n",
    "        images = Variable(images).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if (i+1) % 10 == 0:\n",
    "          print('Loss %.4f' %( loss.data))\n",
    "          print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' %(epoch+1,\n",
    "               num_epochs, i+1, len_train_loader//batch_size, loss.itme()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KOiTt-TciTPB"
   },
   "source": [
    "# Evaluating The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Eh2uzrlj3kn"
   },
   "source": [
    "## general evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E7fS2GqliSMW"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "model.eval()\n",
    "counter = 0\n",
    "\n",
    "# Tell torch not to calculate gradients\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        # Move to device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model.forward(inputs)\n",
    "        \n",
    "        # Calculate Loss\n",
    "        valloss = criterion(output, labels)\n",
    "        \n",
    "        # Add loss to the validation set's running loss\n",
    "        val_loss += valloss.item()*inputs.size(0)\n",
    "\n",
    "        # Since our model outputs a LogSoftmax, find the real \n",
    "        # percentages by reversing the log function\n",
    "        output = torch.exp(output)\n",
    "        \n",
    "        # Get the top class of the output\n",
    "        top_p, top_class = output.topk(1, dim=1)\n",
    "        \n",
    "        # See how many of the classes were correct?\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        # Calculate the mean (get the accuracy for this batch)\n",
    "        # and add it to the running accuracy for this epoch\n",
    "        \n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "        # Print the progress of our evaluation\n",
    "        counter += 1\n",
    "        print(counter, \"/\", len(val_loader))\n",
    "\n",
    "# Get the average loss for the entire epoch\n",
    "train_loss = train_loss/len(train_loader.dataset)\n",
    "valid_loss = val_loss/len(val_loader.dataset)\n",
    "\n",
    "# Print out the information\n",
    "print('Accuracy: ', accuracy/len(val_loader))\n",
    "print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nkXuXyuwkOBP"
   },
   "source": [
    "## image evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgfpaCUxiSWu"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "ans = torch.cuda.LongTensor()\n",
    "\n",
    "for images in test_loader:\n",
    "    images = Variable(images).cuda()\n",
    "    outputs = model(images)\n",
    "    _,predicted = torch.max(outputs.data, 1)\n",
    "    ans = torch.cat((ans,predicted),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdXipyCKiSau"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "YOifJyv_S8d3",
    "tHCidGr8EnIn",
    "QuQ18rFmH5-P",
    "qg-peL2pKxUz",
    "_sfvmfHKSAIp",
    "CXhmNvMwX7EY",
    "KOiTt-TciTPB"
   ],
   "name": "Pytorch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
