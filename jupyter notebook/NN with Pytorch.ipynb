{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net with Pytorch\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torchvision import models\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "print(\"is cuda available :\",torch.cuda.is_available())\n",
    "\n",
    "#basic imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# models\n",
    "from torchvision import models\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomedDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        self.train = train\n",
    "        if self.train :\n",
    "            trainX = pd.read_csv('../input/train.csv')\n",
    "            trainY = trainX.label.as_matrix().tolist()\n",
    "            trainX = np.apply_along_axis(self.preprocess , axis=1 ,\\\n",
    "            arr = trainX.drop('label',axis=1).as_matrix().reshape(trainX.shape[0], 1, 28, 28).astype(np.uint8))\n",
    "            self.datalist = trainX\n",
    "            self.labellist = trainY\n",
    "        else:\n",
    "            testX = pd.read_csv('../input/test.csv')\n",
    "            testX = testX.as_matrix().reshape(testX.shape[0], 1, 28, 28)\n",
    "            self.datalist = testX\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            return torch.Tensor(self.datalist[index].astype(float)),self.labellist[index]\n",
    "        else:\n",
    "            return torch.Tensor(self.datalist[index].astype(float))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.datalist.shape[0]\n",
    "    \n",
    "    def preprocess(self,img):\n",
    "        print(img.shape)\n",
    "        blur = cv2.GaussianBlur(img,(3,3),0)\n",
    "        ret3,th3 = cv2.threshold(blur,120,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        return th3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomedDataSet()\n",
    "\n",
    "test_dataset = CustomedDataSet(train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "len_td = len(train_dataset)\n",
    "\n",
    "# now the required data is in loader\n",
    "del train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# self made model pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1 ,8, kernel_size=3,padding=2),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(8, 32, kernel_size=5,padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, kernel_size=5,padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "#         print(len(out.view(out.size(0), -1)))\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "cnn = CNN()\n",
    "cnn.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Pretrained models\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained = True) # tochvision\n",
    "\n",
    "# display properties\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        \n",
    "        # initiallzing gradient to 0\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #predicting the batch\n",
    "        outputs = cnn(images)\n",
    "        \n",
    "        # difference or loss from actual\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "         if (i + 1)% 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (i + 1) * len(images), len(train_loader.dataset),\n",
    "                100. * (i + 1) / len(train_loader), loss.data[0]))\n",
    "\n",
    "\n",
    "        \n",
    "        # calculating the gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # updating the gradient\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEsting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# staring \n",
    "cnn.eval()\n",
    "\n",
    "ans = torch.cuda.LongTensor()\n",
    "\n",
    "for images in test_loader:\n",
    "    images = Variable(images).cuda()\n",
    "    \n",
    "    #predicting the image\n",
    "    outputs = cnn(images)\n",
    "    \n",
    "    \n",
    "    _,predicted = torch.max(outputs.data, 1)\n",
    "    ans = torch.cat((ans,predicted),0)\n",
    "    \n",
    "    \n",
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in data_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss += F.cross_entropy(output, target, size_average=False).data[0]\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "        \n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ans = ans.cpu().numpy() \n",
    "\n",
    "aa = pd.DataFrame(ans)\n",
    "aa.columns = ['Label']\n",
    "Id = range(1,aa.size+1)\n",
    "aa.insert(0, 'ImageId', Id) \n",
    "\n",
    "aa.head()\n",
    "\n",
    "aa.to_csv('submit_pytorch.csv',index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
